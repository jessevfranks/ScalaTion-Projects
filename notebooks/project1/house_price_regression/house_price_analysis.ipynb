{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## EDA and Preprocessing\\n\",\n",
    "    \"For the House Price dataset, preprocessing was trivial. The dataset comes without outliers or null values, meaning nothing needs to be done here.\\n\",\n",
    "    \"\\n\",\n",
    "    \"After running forwards, backwards, and stepwise selections, features were ranked in importance of:\\n\",\n",
    "    \"1. Square footage\\n\",\n",
    "    \"2. Lot size\\n\",\n",
    "    \"3. Number of bedrooms\\n\",\n",
    "    \"4. Number of bathrooms\\n\",\n",
    "    \"5. Year built\\n\",\n",
    "    \"6. Garage Size\\n\",\n",
    "    \"7. Neighborhood Quality\\n\",\n",
    "    \"\\n\",\n",
    "    \"While all features increased the R^2 value, Neighborhood Quality had a minimal increase (0.00004), and could be left out. Stepwise selection choose not to include this feature in its final list. Because of this, we can drop this column. After rerunning the feature selection methods on the adjusted dataset, stepwise did not include Garage Size since it only increased the R^2 by 0.0002. For now though, we will leave this feature in. On a more complex dataset, it may be good to drop this feature to increase speed and reduce possible noise.\"\n",
    "   ],\n",
    "   \"id\": \"de95cc19d8b66a4a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## Linear Regression\\n\",\n",
    "    \"\\n\",\n",
    "    \"In Linear Regression, we consistently see R^2 values of ~0.991 (in 5-fold cross-validation this is the average), with some variation occurring in the 4th decimal digit. 5-fold cross validation give use the best idea of what to expect from our dataset here. The least accurate fold has an R^2 value of .9710, suggesting that this fold was the most difficult to predict. The highest fold was 0.9931, the best score of any model. Given these two values, we could expect our model to perform somewhere in this range on new data. 5-fold cross validation here is the most robust and realistic option to get an idea of how good our model is. Below is a chart of the results and some metrics:\\n\",\n",
    "    \"\\n\",\n",
    "    \"| Metric | In-Sample (Full) | Train-Test Split (80/20) | 5-Fold Cross-Validation (Avg) |\\n\",\n",
    "    \"| :--- | :--- | :--- | :--- |\\n\",\n",
    "    \"| **$R^2$** | 0.991850 | 0.991850 | 0.991712 |\\n\",\n",
    "    \"| **Adj. $R^2$** | 0.991809 | 0.991809 | 0.991678 |\\n\",\n",
    "    \"| **RMSE** | 22880.23 | 22880.23 | 22889.37 |\\n\",\n",
    "    \"| **MAPE** | 3.968% | 3.968% | ~4.00% |\"\n",
    "   ],\n",
    "   \"id\": \"38c35895bac73e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## Ridge Regression\\n\",\n",
    "    \"In Ridge Regression, we don't see much change. This is expected, as there is low multi-collinearity in the dataset. We suspected this given the \\\"coolness\\\" show in the correlation heatmap. Lambda is also relatively small (by default), meaning that Ridge Regression should not have had an enormous impact on the coefficients anyways. With a R^2 of 0.991801, the results are more or less identical to Linear Regression's\\n\",\n",
    "    \"\\n\",\n",
    "    \"| Variable | OLS (Previous Run) | Ridge (Î»=0.1) | Change |\\n\",\n",
    "    \"| :--- | :--- | :--- | :--- |\\n\",\n",
    "    \"| **Square_Footage** | 199.0866 | 199.0867 | Negligible |\\n\",\n",
    "    \"| **Num_Bedrooms** | 9650.4529 | 9650.0250 | -0.4279 |\\n\",\n",
    "    \"| **Num_Bathrooms** | 7167.8387 | 7166.8555 | -0.9832 |\\n\",\n",
    "    \"| **Year_Built** | -13.5254 | -13.5224 | +0.0030 |\\n\",\n",
    "    \"| **Lot_Size** | 13676.0093 | 13675.2164 | -0.7929 |\\n\",\n",
    "    \"| **Garage_Size** | 4344.7273 | 4344.1877 | -0.5396 |\"\n",
    "   ],\n",
    "   \"id\": \"dbf73f2155e2ef45\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"\",\n",
    "   \"id\": \"3ecfd015eef08955\"\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 2\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython2\",\n",
    "   \"version\": \"2.7.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "b38ccf05c35c08ed"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
